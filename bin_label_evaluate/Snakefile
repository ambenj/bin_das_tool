#!/usr/bin/env python
from os.path import join, abspath, expanduser

# Do I need to add local rules like in the other snakefile?
localrules: bwa_index_setup #,metabat

# Read in sample and outdir from config file
samp = config['sample']
outdir = config['outdir_base']

# are we using a non-standard (non ncbi) taxonomy
if 'custom_taxonomy' in config:
    custom_taxonomy = config['custom_taxonomy']
else:
    custom_taxonomy = False

# convert outdir to absolute path
if outdir[0] == '~':
    outdir = expanduser(outdir)
outdir = abspath(outdir)

# Read in fastq files
if 'reads2' in config and not config['reads2'] == '':
    reads = [config['reads1'], config['reads2']]
else:
    reads = [config['reads1']]

# Determine if long reads
if 'long_read' in config and config['long_read']:
    long_read = True
else:
    long_read = False


def get_metabat_bins(wildcards):
    outputs = checkpoints.metabat.get(**wildcards).output[0]
    return glob_wildcards(os.path.join(outputs, "{metabat_bin}.fa")).metabat_bin

def get_maxbin_bins(wildcards):
    outputs = checkpoints.maxbin.get(**wildcards).output[0]
    return glob_wildcards(os.path.join(outputs, "{maxbin_bin}.fasta")).maxbin_bin

def get_DAStool_bins(wildcards):
    outputs = checkpoints.DAStool.get(**wildcards).output[0]
    return glob_wildcards(os.path.join(outputs, "{bin}.fa")).bin

rule all:
    input:
        reads,
        config['assembly'],
        config['kraken2db'],
        # checkm
        expand(join(outdir, "{samp}/metabat/checkm/checkm.tsv"), samp = config['sample']),
        expand(join(outdir, "{samp}/maxbin/checkm/checkm.tsv"), samp = config['sample']),
        #expand(join(outdir, "{samp}/checkm/checkm.tsv"), samp = config['sample']),
        # Post-processing
        expand(join(outdir, "{samp}/classify/bin_species_calls.tsv"), samp = config['sample']),
        expand(join(outdir, "{samp}/final/{samp}.tsv"), samp = config['sample']),
        expand(join(outdir, "{samp}/final/{samp}_simple.tsv"), samp = config['sample']),
        expand(join(outdir, "{samp}/final/bin_tig_mapping.tsv"), samp = config['sample']),

##########################################
####### Prepping input for binning #######
##########################################

# copy assembly fasta file to working directory
rule bwa_index_setup:
    input:
        config['assembly']
    output:
        join(outdir, "{samp}/idx/{samp}.fa")
    resources:
        mem=1,
        time=1
    threads: 1
    shell: """
        cp {input} {output}
        """

# index assembly file
rule bwa_index:
    input:
        join(outdir, "{samp}/idx/{samp}.fa")
    output:
        join(outdir, "{samp}/idx/{samp}.fa.amb"),
        join(outdir, "{samp}/idx/{samp}.fa.ann"),
        join(outdir, "{samp}/idx/{samp}.fa.bwt"),
        join(outdir, "{samp}/idx/{samp}.fa.pac"),
        join(outdir, "{samp}/idx/{samp}.fa.sa")
    log:
        join(outdir, "{samp}/logs/bwa_index.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=8,
        time=2
    threads: 1
    shell: """
        bwa index {input}
        """

# Align reads to assembly
rule bwa_align:
    input:
        asm = join(outdir, "{samp}/idx/{samp}.fa"),
        reads = reads,
        amb = join(outdir, "{samp}/idx/{samp}.fa.amb"),
        ann = join(outdir, "{samp}/idx/{samp}.fa.ann"),
        bwt = join(outdir, "{samp}/idx/{samp}.fa.bwt"),
        pac = join(outdir, "{samp}/idx/{samp}.fa.pac"),
        sa = join(outdir, "{samp}/idx/{samp}.fa.sa")
    output:
        join(outdir, "{samp}/{samp}.bam")
    log:
        join(outdir, "{samp}/logs/bwa_mem.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=16,
        time=12
    threads: 8
    shell: """
        bwa mem -t {threads} {input.asm}  {input.reads} |samtools sort --threads {threads} > {output}
        """

# Align long reads (not sure if I should keep this)
rule align_lr:
    input:
        join(outdir, "{samp}/idx/{samp}.fa"),
        reads
    log:
        join(outdir, "{samp}/logs/align_lr.log")
    output:
        join(outdir, "{samp}/{samp}_lr.bam")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=48,
        time=6
    threads: 16
    shell: """
        minimap2 -t {threads} -ax map-ont {input} | samtools sort --threads {threads} > {output}
        """

# Generate a depth file from BAM file for MetaBat input
rule metabat_pre:
    input:
        join(outdir, "{samp}/{samp}_lr.bam") if long_read else join(outdir, "{samp}/{samp}.bam") #choose a long read alignment or short read alignment
    output:
        single = join(outdir, "{samp}/{samp}.fa.depth.txt"),
        paired = join(outdir, "{samp}/{samp}.fa.paired.txt"),
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    shell: """
        jgi_summarize_bam_contig_depths --outputDepth {output.single} --pairedContigs {output.paired} --minContigLength 1000 --minContigDepth 1  {input} --percentIdentity 50
        """

#####################################################
################ Binning methods ####################
#####################################################

# Run MetaBat binner
checkpoint metabat:
    input:
        asm = join(outdir, "{samp}/idx/{samp}.fa"),
        depth = join(outdir, "{samp}/{samp}.fa.depth.txt"),
    output:
        directory(join(outdir, "{samp}/metabat/bins/")) #the number of bins is unknown prior to execution
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=64,
        time=24
    threads: 4
    params:
        outstring = join(outdir, "{samp}/metabat/bins/bin")
    shell: """
        metabat2 --seed 1 -t {threads} --unbinned --inFile {input.asm} --outFile {params.outstring} --abdFile {input.depth}
        """

# Run MaxBin2 binner
checkpoint maxbin:
    input:
        contigs = config['assembly'],
        reads1 = reads[0],
        reads2 = reads[1]
    output:
        #summary="{samp}/maxbin/maxbin.summary",
        directory(join(outdir, "{samp}/maxbin/bins"))
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    params:
        outfolder="{samp}/maxbin/"
    resources:
        cores=16,
        time=lambda wildcards, attempt: attempt * 2
    shell:
        """
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}
        cd {params.outfolder}
        run_MaxBin.pl -contig {input.contigs} -out maxbin \
        -reads {input.reads1} -reads2 {input.reads2} -thread {resources.cores}
        mkdir bins/
        mv *.fasta bins/
        """

# Aggregate binning results using DAStool
checkpoint DAStool:
    input:
        lambda wildcards: expand(join(outdir, "{samp}/metabat/bins/{metabat_bin}.fa"), metabat_bin = get_metabat_bins(wildcards), samp = wildcards.samp),
        lambda wildcards: expand(join(outdir, "{samp}/maxbin/bins/{maxbin_bin}.fasta"), maxbin_bin = get_maxbin_bins(wildcards), samp = wildcards.samp),
    output:
        directory(join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins"))
    singularity:
        "shub://ambenj/bin_das_tool:dastool"
    params:
        outfolder="{samp}/DAS_tool"
    resources:
        cores=8
    shell:
        """
        if [ -d {params.outfolder} ]; then rm -r {params.outfolder}; fi
        mkdir -p {params.outfolder}

        # Prepare scaffold2bin file for each set of bins
        Fasta_to_Scaffolds2Bin.sh -e fa -i {wildcards.samp}/metabat/bins/ > {wildcards.samp}/DAS_tool/metabat_scaffold2bin.tsv
        Fasta_to_Scaffolds2Bin.sh -e fasta -i {wildcards.samp}/maxbin/bins > {wildcards.samp}/DAS_tool/maxbin_scaffold2bin.tsv

        DAS_Tool -i {wildcards.samp}/DAS_tool/metabat_scaffold2bin.tsv,{wildcards.samp}/DAS_tool/maxbin_scaffold2bin.tsv \
        -l metabat,maxbin -c {wildcards.samp}/idx/{wildcards.samp}.fa -o {wildcards.samp}/DAS_tool/twomethods \
        --search_engine diamond --threads {resources.cores} --write_bins 1 --write_unbinned 1

        """


#####################################################
###################### CheckM #######################
#####################################################

# checkm for metabat output
rule checkm_metabat:
    input:
        lambda wildcards: expand(join(outdir, "{samp}/metabat/bins/{metabat_bin}.fa"), metabat_bin = get_metabat_bins(wildcards), samp = wildcards.samp)
    output:
        join(outdir, "{samp}/metabat/checkm/checkm.tsv")
    log:
        join(outdir, "{samp}/metabat/logs/checkm.log")
    singularity:
        "shub://bsiranosian/bin_genomes:checkm"
    resources:
        mem=128,
        time=12
    threads: 4
    params:
        binfolder = join(outdir, "{samp}/metabat/bins/"),
        checkmfolder = join(outdir, "{samp}/metabat/checkm/"),
    shell: """
        rm -rf {samp}/checkm/*
        checkm lineage_wf -t {threads} -x fa --tab_table -f {output} {params.binfolder} {params.checkmfolder}
        """

# checkm for maxbin output
rule checkm_maxbin:
    input:
        lambda wildcards: expand(join(outdir, "{samp}/maxbin/bins/{maxbin_bin}.fasta"), maxbin_bin = get_maxbin_bins(wildcards), samp = wildcards.samp)
    output:
        join(outdir, "{samp}/maxbin/checkm/checkm.tsv")
    log:
        join(outdir, "{samp}/maxbin/logs/checkm.log")
    singularity:
        "shub://bsiranosian/bin_genomes:checkm"
    resources:
        mem=128,
        time=12
    threads: 4
    params:
        binfolder = join(outdir, "{samp}/maxbin/bins"),
        checkmfolder = join(outdir, "{samp}/maxbin/checkm/"),
        bin_ex = ".fasta"
    shell: """
        rm -rf {samp}/checkm/*
        checkm lineage_wf -t {threads} -x {params.bin_ex} --tab_table -f {output} {params.binfolder} {params.checkmfolder}
        """

# checkm for DAStool output
rule checkm_DAStool:
    input:
        lambda wildcards: expand(join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa"), bin = get_DAStool_bins(wildcards), samp = wildcards.samp)
    output:
        join(outdir, "{samp}/DAS_tool/checkm/checkm.tsv")
    log:
        join(outdir, "{samp}/DAS_tool/logs/checkm.log")
    singularity:
        "shub://bsiranosian/bin_genomes:checkm"
    resources:
        mem=128,
        time=12
    threads: 4
    params:
        binfolder = join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins"),
        checkmfolder = join(outdir, "{samp}/DAS_tool/checkm/"),
        bin_ex = ".fa"
    shell: """
        rm -rf {samp}/checkm/*
        checkm lineage_wf -t {threads} -x {params.bin_ex} --tab_table -f {output} {params.binfolder} {params.checkmfolder}
        """

#####################################################
############ ANALYSIS OF DAS_TOOL BINS ##############
#####################################################

# Use aragorn to detect tRNA and tmRNA genes
rule aragorn:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa")
    output:
        join(outdir, "{samp}/rna/trna/{bin}.fa.txt")
    log:
        join(outdir, "{samp}/logs/aragorn_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=8,
        time=1
    shell: """
        aragorn -t {input} -o {output}
        """

# Use barrnap to predict ribosomal RNA
rule barrnap:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa")
    output:
        join(outdir, "{samp}/rna/rrna/{bin}.fa.txt")
    log:
        join(outdir, "{samp}/logs/barrnap_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=8,
        time=1
    shell: """
        barrnap {input} > {output}
        """

# Use quast to evaluate genome assemblies
rule quast:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa")
    output:
        join(outdir, "{samp}/quast/{bin}.fa/report.txt")
    log:
        join(outdir, "{samp}/logs/quast_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=8,
        time=1
    params:
        quastfolder = join(outdir, "{samp}/quast/{bin}.fa/"),
        thresholds = "0,10000,50000,100000,250000,500000,1000000,2000000,3000000"
    shell: """
        quast.py -o {params.quastfolder} {input} --contig-thresholds {params.thresholds} --fast
        """

# Use prokka to annotate metagenomes
rule prokka:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa")
    output:
        join(outdir, "{samp}/prokka/{bin}.fa/{samp}_{bin}.fa.gff")
    log:
        join(outdir, "{samp}/logs/prokka_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=48,
        time=1,
    threads: 8
    params:
        prokkafolder = join(outdir, "{samp}/prokka/{bin}.fa"),
        prefix = "{samp}_{bin}.fa"
    shell: """
        prokka {input} --outdir {params.prokkafolder} --prefix {params.prefix} \
        --centre X --compliant --force --cpus {threads} --noanno
        """

# Index bam file to prepare for bamidx
rule bam_idx:
    input:
        join(outdir, "{samp}/{samp}_lr.bam") if long_read else join(outdir, "{samp}/{samp}.bam") #choose a long read alignment or short read alignment
    output:
        join(outdir, "{samp}/{samp}_lr.bam.bai") if long_read else join(outdir, "{samp}/{samp}.bam.bai") #choose a long read alignment or short read alignment
    log:
        join(outdir, "{samp}/logs/bamidx.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=2,
        time=2
    shell:
        "samtools index {input}"

# Retrieve stats on mapping from whole metagenome sample
rule bam_idxstats:
    input:
        join(outdir, "{samp}/{samp}_lr.bam") if long_read else join(outdir, "{samp}/{samp}.bam"), #choose a long read alignment or short read alignment,
        join(outdir, "{samp}/{samp}_lr.bam.bai") if long_read else join(outdir, "{samp}/{samp}.bam.bai"), #choose a long read alignment or short read alignment,
    output:
        join(outdir, "{samp}/{samp}_lr.bam.bai.tsv") if long_read else join(outdir, "{samp}/{samp}.bam.bai.tsv"), #choose a long read alignment or short read alignment,
    log:
        join(outdir, "{samp}/logs/bamidxstats.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=2,
        time=2
    shell:
        "samtools idxstats {input[0]} > {output}"

# Get mapping stats for each bin
rule bin_idxstats:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa"),
        join(outdir, "{samp}/{samp}_lr.bam.bai.tsv") if long_read else join(outdir, "{samp}/{samp}.bam.bai.tsv"), #choose a long read alignment or short read alignment,
    output:
        join(outdir, "{samp}/coverage/raw/{bin}.tsv")
    log:
        join(outdir, "{samp}/logs/coverage_idxstats_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=2,
        time=1
    shell:
        "grep '>' {input[0]} | tr -d '>' | xargs -I foo -n 1 grep -P 'foo\t' {input[1]} > {output}"

# Determine coverage for each bin
rule bin_coverage:
    input:
        rules.bin_idxstats.output
    output:
        join(outdir, "{samp}/coverage/{bin}.txt")
    log:
        join(outdir, "{samp}/logs/coverage_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=2,
        time=1
    params:
        read_length = config['read_length']
    script:
        "scripts/bin_coverage.py"

# index DAStool bins
rule fasta_index:
    input:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa")
    output:
        join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa.fai")
    log:
        join(outdir, "{samp}/logs/faidx_{bin}.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    resources:
        mem=8,
        time=1
    threads: 1
    shell:
        "samtools faidx {input}"

# Use kraken2 to assign taxonomic labels
rule kraken2:
    input:
        join(outdir, "{samp}/idx/{samp}.fa")
    output:
        krak = join(outdir, "{samp}/classify/{samp}.krak"),
        krak_report = join(outdir, "{samp}/classify/{samp}.krak.report")
    log:
        join(outdir, "{samp}/logs/kraken_class.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    params:
        db = config['kraken2db']
    resources:
        mem=256,
        time=1
    threads: 8
    shell: """
        kraken2 --db {params.db} --db {params.db} --threads {threads} \
        --output {output.krak} --report {output.krak_report} {input}
        """

rule label_bins:
    input:
        krak = join(outdir, "{samp}/classify/{samp}.krak"),
        bins = lambda wildcards: expand(join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/{bin}.fa.fai"),
                                        bin = get_DAStool_bins(wildcards), samp = wildcards.samp)
    output:
        join(outdir, "{samp}/classify/bin_species_calls.tsv")
    log:
        join(outdir, "{samp}/logs/assign_species.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    params:
        binfolder = join(outdir, "{samp}/DAS_tool/twomethods_DASTool_bins/"),
        custom_taxonomy = custom_taxonomy
    script:
        "scripts/assign_species.py"

rule postprocess_raw:
    input:
        join(outdir, "{samp}/DAS_tool/checkm/checkm.tsv"),
        lambda wildcards: expand(rules.prokka.output, bin = get_DAStool_bins(wildcards), samp = wildcards.samp),
        lambda wildcards: expand(rules.quast.output, bin = get_DAStool_bins(wildcards), samp = wildcards.samp),
        lambda wildcards: expand(rules.aragorn.output, bin = get_DAStool_bins(wildcards), samp = wildcards.samp),
        lambda wildcards: expand(rules.barrnap.output, bin = get_DAStool_bins(wildcards), samp = wildcards.samp),
        lambda wildcards: expand(rules.bin_coverage.output, bin = get_DAStool_bins(wildcards), samp = wildcards.samp),
        rules.label_bins.output
    output:
        prokka = join(outdir, "{samp}/final/prokka.tmp"),
        quast = join(outdir, "{samp}/final/quast.tmp"),
        checkm = join(outdir, "{samp}/final/checkm.tmp"),
        trna = join(outdir, "{samp}/final/trna.tmp"),
        rrna = join(outdir, "{samp}/final/rrna.tmp"),
        classify = join(outdir, "{samp}/final/classify.tmp"),
        coverage = join(outdir, "{samp}/final/coverage.tmp"),
    log:
        join(outdir, "{samp}/logs/postprocess.log")
    resources:
        mem=2,
        time=1
    params:
        coverage_str = join(outdir, "{samp}/coverage/*.txt"),
        prokka_str = join(outdir, "{samp}/prokka"),
        quast_str = join(outdir, "{samp}/quast/"),
        checkm_str = join(outdir, "{samp}/DAS_tool/checkm/checkm.tsv"),
        trna_str = join(outdir, "{samp}/rna/trna/*"),
        rrna_str = join(outdir, "{samp}/rna/rrna/*"),
        kraken_str = join(outdir, "{samp}/classify/bin_species_calls.tsv"),

    shell: """
        # coverage
        (echo -e 'Sample\tBin\tCoverage'; cat {params.coverage_str}) > {output.coverage}
        # prokka
        (echo -e 'Sample\tBin\tGenes'; find {params.prokka_str} -name '*.gff' | xargs grep -H -c CDS | rev | cut -f1 -d '/' | rev | sed 's/.fa.gff:/\t/g' | sed 's/{samp}_/{samp}\t/g' | sort -k2,2g) > {output.prokka}
        # quast
        find {params.quast_str} -name 'transposed_report.tsv' | xargs head -qn1 | sort -u | sed 's/^Assembly/Sample\tBin/g' > {output.quast}
        find {params.quast_str} -name 'transposed_report.tsv' | xargs tail -qn+2 | sort -u | sed 's/^/{samp}\t/g' >> {output.quast}
        # checkm
        head -qn1 {params.checkm_str} | sed 's/^Bin Id/Sample\tBin/g' > {output.checkm}
        tail -qn+2 {params.checkm_str} | sed 's/^/{samp}\t/g' >> {output.checkm}
        # trna
        (echo -e 'Sample\tBin\ttRNA'; grep -H Total {params.trna_str} | sed 's/\/rna\/trna\//\t/g' | sed 's/.fa.txt:Total tRNA genes = /\t/g' | awk '{{ print  gensub( ".*/", "", "a") }}' ) > {output.trna}
        #rrna
        (echo -e 'Sample\tBin\trna.16S\trna.23S\trna.5S'; paste <(grep -H -c 16S {params.rrna_str} | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g') \
        <(grep -H -c 23S {params.rrna_str} | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g' | cut -f4) \
        <(grep -H -c 5S {params.rrna_str} | sed 's/\/rna\/rrna\//\t/g' | sed 's/.fa.txt:/\t/g' | cut -f4)) |  awk '{{ print  gensub( ".*/", "", "a") }}' > {output.rrna}
        # classify
        cat {params.kraken_str} | sed 's/\.fa//g' > {output.classify}
        """

rule postprocess_final:
    input:
        prokka = join(outdir, "{samp}/final/prokka.tmp"),
        quast = join(outdir, "{samp}/final/quast.tmp"),
        checkm = join(outdir, "{samp}/final/checkm.tmp"),
        trna = join(outdir, "{samp}/final/trna.tmp"),
        rrna = join(outdir, "{samp}/final/rrna.tmp"),
        classify = join(outdir, "{samp}/final/classify.tmp"),
        coverage = join(outdir, "{samp}/final/coverage.tmp"),
    output:
        join(outdir, "{samp}/final/{samp}.tsv")
    log:
        join(outdir, "{samp}/logs/postprocess.log")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    script:
        "scripts/join_final_tables.R"

rule postprocess_simplify:
    input:
        join(outdir, "{samp}/final/{samp}.tsv")
    output:
        join(outdir, "{samp}/final/{samp}_simple.tsv")
    shell: """
        # awk 'BEGIN {{FS="\t"}} {{OFS="\t"}} {{print($1,$2,$47,$50,$48,$49,$51,$40,$41,$42,$4,$23,$25,$26)}}' {input} > {output}
        awk 'BEGIN {{FS="\t"}} {{OFS="\t"}} {{print($2,$1,$48,$49,$50,$51,$52,$53,$47,$54,$40,$41,$42,$4,$23,$25,$26)}}' {input} > {output}
        """

rule bin_tig_mapping:
    input:
        rules.postprocess_final.output
    output:
        join(outdir, "{samp}/final/bin_tig_mapping.tsv")
    singularity:
        "shub://bsiranosian/bin_genomes:binning"
    shell:
        "ls {samp}/DAS_tool/twomethods_DASTool_bins/ | grep fai  | xargs -n 1 -I foo sh -c \"cat {samp}/bins/foo | sed 's/^/foo\t/g' \" | sed 's/.fa.fai//g' | cut -f1,2 > {output}"
